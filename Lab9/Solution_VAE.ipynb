{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec156da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.datasets as dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766a859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "image_size = 784\n",
    "h_dim = 400\n",
    "z_dim = 20\n",
    "num_epochs = 15\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce94846e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = dataset.MNIST(\"./\", train=True, transform=transforms.ToTensor(),  download=True)\n",
    "mnist_val  = dataset.MNIST(\"./\", train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = mnist_train,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5914c9",
   "metadata": {},
   "source": [
    "**[TO DO]** \n",
    "\n",
    "Now we will implement the variational autoencoder. The autoencoder uses linear layers. The encoder has a single linear layer with a ReLU activation funtion which projects the flattened image into a hidden dimension of 400.  \n",
    "\n",
    "- Define the decoder at the `__init__` funtion\n",
    "- Fill in the `encode` and `reparameterize` funtions. Define the appropriate layers for them in the `__init__` function. The latent dimension of the mean and standard deviation is 20. The decoder consists of 2 linear layers, the first which projects the latent dimension to the hidden dimension with a ReLU activation funtion, and the second which projects the result to a dimension which equals to the image size. \n",
    "- Define the forward funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8284bc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_size=784, h_dim=400, z_dim=20):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(nn.Linear(image_size, h_dim), \n",
    "                                     nn.ReLU())\n",
    "        \n",
    "        self.mean = nn.Linear(h_dim, z_dim)\n",
    "        self.var = nn.Linear(h_dim, z_dim)\n",
    "        \n",
    "        self.decoder =  nn.Sequential(nn.Linear(z_dim, h_dim), \n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Linear(h_dim, image_size),\n",
    "                                      nn.Sigmoid())\n",
    "        \n",
    "    def encode(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        mu, var = self.mean(latent), self.var(latent)\n",
    "        return mu, var\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(log_var / 2)   # assume that they are log-based\n",
    "        eps = torch.randn(*std.shape).to(device)\n",
    "        return mu + std * eps\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, var = self.encode(x)\n",
    "        x = self.reparameterize(mu, var)\n",
    "        x = self.decode(x)\n",
    "        return x, mu, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992c2f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "mse_loss = nn.MSELoss(reduction = 'sum')\n",
    "\n",
    "# can use mean reduction, but then KLD should be:\n",
    "# kld_loss = torch.mean(-0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp(), dim = 1), dim = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3560105",
   "metadata": {},
   "source": [
    "**[TO DO]** Write the loss term which consists of both the reconstruction loss and the KL divergence loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d80a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (x, _) in enumerate(train_loader):\n",
    "        # Forward pass   \n",
    "        image = x.to(device).view(-1, image_size)   # (batch_size, 1, 28, 28) -->\n",
    "        x_reconst, mu, log_var = model(image)\n",
    "        \n",
    "        # Compute reconstruction loss and kl divergence\n",
    "        reconst_loss = mse_loss(x_reconst, image)\n",
    "        kl_div = 0.5 * torch.sum(torch.exp(log_var) + mu**2 - 1 - log_var)\n",
    "        loss = reconst_loss + kl_div\n",
    "        \n",
    "        # Backprop and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print (\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}\" \n",
    "                   .format(epoch+1, num_epochs, i+1, len(train_loader), reconst_loss.item(), kl_div.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c499d50",
   "metadata": {},
   "source": [
    "**[TO DO]** Generate new samples. Sample the latent vector from the normal distribution and feed it to the decoder. Make sure to reshape your flattened output image to 2D for visualization! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5961b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate new images\n",
    "\n",
    "num_images = 10\n",
    "latent = torch.randn(num_images, z_dim).to(device)\n",
    "gen_images = model.decoder(latent)\n",
    "gen_images = gen_images.reshape(num_images, 28, 28)\n",
    "gen_images = gen_images.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae7486b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, num_images, figsize=(20,10))\n",
    "np.vectorize(lambda ax:ax.axis('off'))(axs)\n",
    "for i in range(num_images):\n",
    "    axs[i].imshow(gen_images[i], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed934949",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
