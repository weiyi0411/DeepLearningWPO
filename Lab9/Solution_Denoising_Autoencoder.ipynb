{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8446184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils as utils\n",
    "import torchvision.datasets as dataset\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91361005",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = dataset.MNIST(\"./\", train=True, transform=transforms.ToTensor(),  download=True)\n",
    "mnist_val  = dataset.MNIST(\"./\", train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = mnist_train,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset = mnist_val,\n",
    "                                         batch_size = batch_size,\n",
    "                                         shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9929efc9",
   "metadata": {},
   "source": [
    "Let's explore the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9052cc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 6, figsize=(20,5))\n",
    "np.vectorize(lambda ax:ax.axis('off'))(axs)\n",
    "\n",
    "for i in range(6):\n",
    "    axs[i].imshow(mnist_train[i][0].squeeze().numpy(), cmap = 'gray')\n",
    "    axs[i].set_title(\"Label: {}\".format(mnist_train[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9f3ea0",
   "metadata": {},
   "source": [
    "**[TO DO]** Create a funtion which samples gaussian noise with a given mean and standard deviation. This will be used to corrupt the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2680c130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_noise(mean, std, shape):\n",
    "    noise = torch.randn(shape) * std + mean \n",
    "    return noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9378f64",
   "metadata": {},
   "source": [
    "**[To DO]** Build a Convolutional Autoencoder\n",
    "\n",
    "- The Encoder is composed of three convolutional layers, each separated by a ReLU activation function. These layers are configured with output channels (or number of filters) in the following sequence: [32, 32, 64].\n",
    "- The Decoder consists of three convolutional layers with a ReLU activation funtion in-between. However, the number of output channels here is the reverse of the Encoder's configuration. Additionally, the Decoder employs [Pixel Shuffle](https://pytorch.org/docs/stable/generated/torch.nn.PixelShuffle.html) after each of the first two convolutional layers to upsample the input (therefore, make sure to predict $s^2$ channels for **each** output channel, which are to be allocated by Pixel Shuffle.) Use an upscale factor $s = 2$ for each of the two Pixel Shuffle Layers. The final convolutional layer in the Decoder reduces the output channels to match the number of channels in the target image. It is essential to ensure that the Decoder's output generates an image that matches the input image in shape, since we use a mean squared error reconstruction term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fd677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder,self).__init__()\n",
    "        # 32, 32, 64\n",
    "        self.encoder = nn.Sequential(nn.Conv2d(1, 32, 3, stride=2, padding=1), #  batch, 32, 14x14\n",
    "                                     nn.ReLU(),                                #  batch, 32, 14x14\n",
    "                                     nn.Conv2d(32, 32, 3, stride=2, padding=1),# batch,  32, 7 x 7\n",
    "                                     nn.ReLU(),                                # batch,  32, 7 x 7\n",
    "                                     nn.Conv2d(32, 64, 3, stride=1, padding=1)) # batch,  64, 7 x 7\n",
    "        \n",
    "        # 64, 32, 32\n",
    "        upscale_factor = 2\n",
    "        self.decoder = nn.Sequential(nn.Conv2d(64, 32 * (upscale_factor ** 2), 3, stride=1, padding=1),  # (batch, 32, 7, 7)\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.PixelShuffle(upscale_factor),  # (batch, 32, 14x14)\n",
    "                                     nn.Conv2d(32, 32 * (upscale_factor ** 2), 3, stride=1, padding=1), \n",
    "                                     nn.ReLU(),\n",
    "                                     nn.PixelShuffle(upscale_factor),  # (batch, 32, 28,28),\n",
    "                                     nn.Conv2d(32, 1, 3, stride=1, padding=1))\n",
    "                                 \n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b64a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_loss, val_loss):\n",
    "\n",
    "    epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "    plt.plot(epochs, train_loss, '--', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cd4168",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 5\n",
    "\n",
    "model = AutoEncoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453cc9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pay attention that for the validation set we are generating noise once, to do a consistent calculation of the validation loss \n",
    "val_noise = gaussian_noise(mean=0, std=0.5, shape=(batch_size, 1, 28, 28)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b8d1af",
   "metadata": {},
   "source": [
    "**[TO DO]** Fill in the missing parts. These include:\n",
    "\n",
    "- Constructing the training input image \n",
    "- Calcualting the loss\n",
    "- Constructing the validation input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0c449e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    model.train()\n",
    "    epoch_loss_train = 0\n",
    "    epoch_loss_val = 0\n",
    "    \n",
    "    for image,_ in train_loader:\n",
    "        # Pay attention that for the training set we are generating noise at for every batch.\n",
    "        input_image = image.to(device)\n",
    "        train_noise = gaussian_noise(mean = 0, std = 0.5, shape = input_image.shape).to(device)\n",
    "        noisy_input = input_image + train_noise\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(noisy_input)\n",
    "\n",
    "        loss = criterion(outputs, input_image)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss_train += loss.item()\n",
    "        \n",
    "    train_loss = epoch_loss_train / len(train_loader)\n",
    "    training_losses.append(train_loss)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for val_image, _ in val_loader:\n",
    "        \n",
    "        input_image = val_image.to(device)\n",
    "        noisy_input = input_image + val_noise\n",
    "        \n",
    "        outputs = model(noisy_input)\n",
    "        val_loss = criterion(outputs,input_image)\n",
    "        epoch_loss_val += val_loss.item()\n",
    "        \n",
    "    val_loss = epoch_loss_val / len(val_loader)\n",
    "    validation_losses.append(val_loss)\n",
    "              \n",
    "                \n",
    "    print(\"Training loss:\",epoch_loss_train / len(train_loader),\n",
    "          \" Validation loss:\", epoch_loss_val / len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530b4f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(train_loss=training_losses, val_loss=validation_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260e8c35",
   "metadata": {},
   "source": [
    "Visualize the output. Take a random sample from the validation set, corrupt it with noise and run the noisy image through the model. Does the model remove noise from this image? Rememeber to move the channels of the PyTorch Tensor to the end (as what numpy expects), move your Tensor to the CPU and convert it to numpy! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6c661d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "images, _ = next(iter(val_loader))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19251e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 3\n",
    "input_image = images[index].unsqueeze(0).to(device)\n",
    "noisy_image = input_image + val_noise\n",
    "result = model(noisy_image)\n",
    "\n",
    "original = images[index].permute(1,2,0).detach().cpu().numpy()\n",
    "noisy_image =  noisy_image[0].permute(1,2,0).detach().cpu().numpy()\n",
    "result = result[0].permute(1,2,0).detach().cpu().numpy()\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20,5))\n",
    "np.vectorize(lambda ax:ax.axis('off'))(axs)\n",
    "axs[0].imshow(original, cmap = 'gray')\n",
    "axs[1].imshow(noisy_image, cmap = 'gray')\n",
    "axs[2].imshow(result, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9496e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
