{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a14837b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "055b7b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")   # use GPU if available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdcdc68",
   "metadata": {},
   "source": [
    "## **Warmup Exercises**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9be2ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4087, -0.8977, -0.5590,  2.0335,  1.0063],\n",
       "         [ 1.8984, -0.2633,  0.0252,  1.7775,  0.5284],\n",
       "         [-0.4471,  0.8396, -1.3039,  1.2150,  1.7191],\n",
       "         [-0.1944, -1.1533,  0.4767, -0.0801,  1.3584],\n",
       "         [ 1.3358,  1.1212, -0.9982,  1.9079,  0.2062]],\n",
       "\n",
       "        [[ 1.5582, -1.2031,  0.5682,  0.8463, -0.3713],\n",
       "         [-1.6906, -0.2856,  0.5294,  0.3256, -2.0775],\n",
       "         [ 1.4707,  0.8503,  0.1308, -0.9875, -0.4715],\n",
       "         [ 0.8590,  1.0694, -0.5381, -0.8723, -0.4405],\n",
       "         [-1.1014, -2.4246,  1.3078,  0.9617, -0.1486]],\n",
       "\n",
       "        [[-0.6786, -1.2791, -0.8645,  1.0667, -0.1196],\n",
       "         [-0.6891, -0.6406,  1.5202,  1.5707, -0.7599],\n",
       "         [ 0.0390,  1.3539,  0.5610, -2.1026, -0.3495],\n",
       "         [-0.5113, -0.9394,  0.8939,  0.4001, -0.6020],\n",
       "         [ 1.3717,  0.9289,  0.7351, -0.8939,  0.2392]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a random tensor\n",
    "x = torch.randn(3,5,5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc94793e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c803b14f",
   "metadata": {},
   "source": [
    "What will be the output of a Max Pooling Operation (using [torch.nn.functional.max_pool2d](https://pytorch.org/docs/stable/generated/torch.nn.functional.max_pool2d.html)) with a kernal size of 3x3 and a stride of 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e4d7ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.8984, 2.0335],\n",
      "         [1.3358, 1.9079]],\n",
      "\n",
      "        [[1.5582, 0.8463],\n",
      "         [1.4707, 1.3078]],\n",
      "\n",
      "        [[1.5202, 1.5707],\n",
      "         [1.3717, 0.8939]]])\n",
      "torch.Size([3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "result = F.max_pool2d(x, 3, 2)\n",
    "print(result)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70736834",
   "metadata": {},
   "source": [
    "Now do the same but using [nn.MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html). Do you get the same result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62a75bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.8984, 2.0335],\n",
      "         [1.3358, 1.9079]],\n",
      "\n",
      "        [[1.5582, 0.8463],\n",
      "         [1.4707, 1.3078]],\n",
      "\n",
      "        [[1.5202, 1.5707],\n",
      "         [1.3717, 0.8939]]])\n",
      "torch.Size([3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "maxpool_layer = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "result = maxpool_layer(x)\n",
    "print(result)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dd6cf5",
   "metadata": {},
   "source": [
    "See [this](https://ezyang.github.io/convolution-visualizer/) for a nice visualization of convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c372d7b",
   "metadata": {},
   "source": [
    "Now we will explore using the [nn.Conv2D](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) funtion. It takes the following parameters: \n",
    "<br>\n",
    "`nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc5cbb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a random RGB tensor of size 10x10\n",
    "x = torch.rand(4,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b98dfbc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 10])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2bb8ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "# apply a convolutional layer with 5 filters, each of size 3x3, with a stride of 1. What will be the shape?\n",
    "conv_layer = nn.Conv2d(4, 5, 3, stride=1)\n",
    "print(conv_layer(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052cb544",
   "metadata": {},
   "source": [
    "The spatial dimension has reduced to 8x8. Why? Can you fix it so that the spatial dimension does not change?\n",
    "<br>\n",
    "<br>\n",
    "**Recall**: Formula for *same padding*: $\\dfrac{kernel size - 1}{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "843051d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "conv_layer = nn.Conv2d(4, 5, 3, stride=1, padding = 1)\n",
    "print(conv_layer(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c596753",
   "metadata": {},
   "source": [
    "What is the shape of the weights for the convolutional layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1e9de0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 4, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(conv_layer.weight.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604226a1",
   "metadata": {},
   "source": [
    "Now assume you have an input with a batch size of 16, 20 channels, and a spatial dimension of 100x60. You want your resulting output tensor after Max Pooling to be of shape (16, 20, 25, 25). What parameters of the Max Pooling would you choose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09c7d786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 20, 25, 25])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(16, 20, 100, 100)\n",
    "\n",
    "maxpool_layer = nn.MaxPool2d(kernel_size=4, stride=4)\n",
    "output1 = maxpool_layer(input)\n",
    "print(output1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ba5769",
   "metadata": {},
   "source": [
    "Can you achieve the same thing but using the stride of a convolution operator instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec7f6f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 20, 25, 25])\n"
     ]
    }
   ],
   "source": [
    "conv_layer = nn.Conv2d(20, 20, 3, stride=4, padding = 1)\n",
    "output2 = conv_layer(input)\n",
    "print(output2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dc0a32",
   "metadata": {},
   "source": [
    "### Convolutional Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1f9106",
   "metadata": {},
   "source": [
    "#### Part 1: Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ad8265",
   "metadata": {},
   "source": [
    "1. Data Transforms\n",
    "\n",
    "Use [torchvision.transforms](https://pytorch.org/vision/0.9/transforms.html) as a reference. Apply data transformations to the training images such that you\n",
    "- Crop a random portion of image and resize it to a size of 32x32\n",
    "- Apply random horizantal flipping as a data augmentation strategy. You can check other data augmentations [here](https://pytorch.org/vision/main/auto_examples/transforms/plot_transforms_illustrations.html#sphx-glr-auto-examples-transforms-plot-transforms-illustrations-py)\n",
    "- Transform it to a PyTorch Tensor with scaled values between 0-1\n",
    "- Standardize it such that it has a mean of zero and standard deviation of 1\n",
    "\n",
    "For the test images, only perform the last two steps\n",
    "\n",
    "Note: \n",
    "- The mean of the CIFAR dataset for each of the RGB Channels is: `(0.4914, 0.4822, 0.4465)`\n",
    "- The standard deviation of the CIFAR dataset for each of the RGB channels is: `(0.2023, 0.1994, 0.2010)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5f533b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([transforms.RandomResizedCrop(32),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "transform_test = transforms.Compose([transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee0c6d3",
   "metadata": {},
   "source": [
    "We will work with the CIFAR10 dataset. It is a dataset of 60,000 32x32 colour images in 10 classes, with 6000 images per class. There are 50,000 training images and 10,000 test images.\n",
    "\n",
    "2. Load (and download if you havent already done so) the training and testing datasets using [torchvision.datasets](https://pytorch.org/vision/main/generated/torchvision.datasets.CIFAR10.html). Specify the transforms that you have already defined in the previous step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6424760d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9c1b28",
   "metadata": {},
   "source": [
    "3. Define your data loader. Use a batch size of 128 for training and 100 for testing. Make sure you shuffle the data loading process in the training set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76472807",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a7589a",
   "metadata": {},
   "source": [
    "Let's visualize some of the images from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a73b249",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def imshow(inp):\n",
    "    \"\"\"Display image from a PyTorch Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.4914, 0.4822, 0.4465])\n",
    "    std = np.array([0.2023, 0.1994, 0.2010])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1920c78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 32, 32])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "# get some random training images\n",
    "images, labels = next(iter(trainloader))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd91a800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 9, 6, 4])\n",
      "dog, truck, frog, deer\n"
     ]
    }
   ],
   "source": [
    "# let's have a look at the labels for the first 4 loaded images \n",
    "print(labels[:4])\n",
    "# if we would like to map them to human-readble text labels\n",
    "print(', '.join([classes[labels[b]] for b in range(4)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5f24fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxoAAADcCAYAAAD3GddmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABNqUlEQVR4nO29ebCmV1n2ez3jO+13791795hO0iQhjCcEDCZIEAwYiYSIQkBRSEKZEpBTViklkCNKQIpRLCk+RaxTDBZDAKU0mioEw/CBNEpAwhBIYpJOeu49D+/wjOv80V/60KzrpncnT5MA16+KP7j36vWutZ41PGvv3L83cM45CCGEEEIIIUSDhA91A4QQQgghhBA/feiiIYQQQgghhGgcXTSEEEIIIYQQjaOLhhBCCCGEEKJxdNEQQgghhBBCNI4uGkIIIYQQQojG0UVDCCGEEEII0Ti6aAghhBBCCCEaRxcNIYQQQgghROPoovFj5vrrr0cQBA91M4Q4pXzlK1/B9ddfj+Xl5Yfk8z/4wQ8iCALccsstD8nnC3GyfPzjH8fjH/94dDodBEGAb37zmw91k4R4WKH3p59MdNEQQjTOV77yFbzxjW98yC4aQvwkMTc3h5e+9KU455xz8OlPfxq7d+/Gox71qIe6WUII8aCJH+oGCCF+thmNRuh0Og91M4R4yLjjjjtQFAVe8pKX4BnPeIZZbjgcotvt/hhbJsTPNlpzDx79ReMUctNNN+GJT3wiWq0WzjrrLPzFX/yFV2Y8HuO6667DWWedhTRNsXPnTrzqVa/yfhOcZRle/epXY/v27eh2u3j605+Or3/963jEIx6Ba6655sfTISE2wPXXX48//uM/BgCcddZZCIIAQRDgC1/4Ah7xiEfguc99Lj71qU/hSU96EtrtNt74xjdiz549CIIAH/zgB736giDA9ddff1zs+9//Pl784hdj27ZtaLVaOPPMM3HVVVchyzKzXQcPHsQFF1yAc889F3feeWeTXRbiAXPNNdfgaU97GgDgN3/zNxEEAX7pl34J11xzDSYmJvDtb38bv/Irv4J+v49nPetZAIDFxUX8/u//Pnbu3Ik0TXH22WfjT/7kT7z5v7y8jN/93d/FzMwMJiYmcPnll+Puu++ma0qIhxMbeX9yzuFv/uZv8MQnPhGdTgebNm3ClVdeibvvvtsr++///u941rOehcnJSXS7XVx88cW4+eabjytz/3+a9Y1vfANXXnklNm3ahHPOOeeU9fFnBf1F4xRx880343nPex5+4Rd+ATfccAOqqsI73vEOHD58+FgZ5xx+/dd/HTfffDOuu+46/OIv/iK+9a1v4Q1veAN2796N3bt3o9VqAQBe9rKX4eMf/zhe85rX4JnPfCZuu+02/MZv/AZWV1cfqi4KQbn22muxuLiI97znPfjUpz6FHTt2AAAe97jHAQC+8Y1v4Hvf+x5e//rX46yzzkKv1zup+m+99VY87WlPw+bNm/GmN70J5557Lg4ePIgbb7wReZ4fWzM/yHe+8x085znPwemnn47du3dj8+bND76jQjTAn/7pn+LCCy/Eq171KrzlLW/BJZdcgsnJSbzjHe9Anuf4tV/7Nbz85S/H6173OpRlifF4jEsuuQR33XUX3vjGN+IJT3gCvvSlL+Gtb30rvvnNb+Kmm24CANR1jSuuuAK33HILrr/+evzcz/0cdu/ejcsuu+wh7rEQP5qNvD8BwMtf/nJ88IMfxB/8wR/g7W9/OxYXF/GmN70JT33qU3Hrrbdi27ZtAIAPf/jDuOqqq/C85z0PH/rQh5AkCd73vvfh2c9+Nv7t3/7t2AX+fp7//Ofjt37rt/CKV7wCg8Hgx9bvn1qcOCVcdNFF7rTTTnOj0ehYbHV11c3MzLj7h/3Tn/60A+De8Y53HPdvP/7xjzsA7u/+7u+cc85997vfdQDca1/72uPKfexjH3MA3NVXX31qOyPESfLOd77TAXD33HPPcfFdu3a5KIrc7bffflz8nnvucQDcBz7wAa8uAO4Nb3jDsf//zGc+001PT7sjR46Yn/+BD3zAAXBf+9rX3Gc/+1k3OTnprrzyyuPWoxAPFz7/+c87AO6Tn/zksdjVV1/tALj3v//9x5X927/9WwfAfeITnzgu/va3v90BcJ/5zGecc87ddNNNDoB773vfe1y5t771rd6aEuLhxEben3bv3u0AuHe9613H/du9e/e6TqfjXvOa1zjnnBsMBm5mZsZdccUVx5Wrqsqdf/757sILLzwWe8Mb3uAAuD/7sz87VV37mUT/6dQpYDAY4Gtf+xqe//zno91uH4v3+31cccUVx/7/5z73OQDw/tOnF77whej1esf+rPfFL34RAPCiF73ouHJXXnkl4lh/lBI/WTzhCU94wImuw+EQX/ziF/GiF70IW7ZsOWH5D33oQ3jOc56Da6+9Fp/4xCeOW49C/CTwghe84Lj//7nPfQ69Xg9XXnnlcfH7z5ETnRsvfvGLT1FLhXjwbPT96V//9V8RBAFe8pKXoCzLY//bvn07zj//fHzhC18AcFRMsri4iKuvvvq4cnVd47LLLsPXvvY1768WP7zmxINDb6mngKWlJdR1je3bt3s/+8HYwsIC4jj2XpiCIMD27duxsLBwrByAY38GvJ84jjE7O9t084U4pdz/n1I9EJaWllBVFU4//fQNlb/hhhvQ6XRw7bXXSosofuLodruYnJw8LrawsIDt27d783nr1q2I4/i4cyOOY8zMzBxX7ofPESEeTmz0/enw4cNwzpnz+eyzzz5WDoB3Mf9BFhcXj/tPeB/MGSV8dNE4BWzatAlBEODQoUPez34wNjs7i7IsMTc3d9xlwzmHQ4cO4ed//uePlQOOLpidO3ceK1eW5bFDRYifFNgL//2/ufrhZNYfnt8zMzOIogj79u3b0Gd95CMfwetf/3o84xnPwGc+8xk88YlPfGCNFuIhgK2V2dlZ/Od//iecc8f9/MiRIyjL8lj+0f3ny+Li4nGXDXYuCfFwYaPvT5s3b0YQBPjSl75E8/Luj92/Ht7znvfgKU95Cv3MH76s6JdSzaL/dOoU0Ov1cOGFF+JTn/oUxuPxsfja2hr+5V/+5dj/vz8B6cMf/vBx//4f//EfMRgMjv386U9/OoCjX+j0g/zDP/wDyrI8JX0Q4sFw/yY/Go02VH7btm1ot9v41re+dVz8n//5n4/7/51OB894xjPwyU9+EvPz8yesd2ZmBjfffDMe+9jH4pJLLsFXv/rVDfZAiIcnz3rWs7C+vo5/+qd/Oi7+93//98d+DuCYJveHz40bbrjh1DdSiAfIRt+fnvvc58I5h/379+PJT36y97/zzjsPAHDxxRdjenoat912Gy335Cc/GWma/tj7+bOE/qJxivjzP/9zXHbZZbj00kvx6le/GlVV4e1vfzt6vR4WFxcBAJdeeime/exn47WvfS1WV1dx8cUXH7NOPelJT8JLX/pSAMDjH/94vPjFL8a73vUuRFGEZz7zmfjud7+Ld73rXZiamkIY6r4oHl7cv8m/+93vxtVXX40kSfDoRz/aLH//f2v7/ve/H+eccw7OP/98/Nd//Rc++tGPemX/8i//Ek972tNw0UUX4XWvex0e+chH4vDhw7jxxhvxvve9D/1+/7jy/X4fn/70p/H85z8fl156KW688UZccsklzXZYiB8TV111Ff76r/8aV199Nfbs2YPzzjsPX/7yl/GWt7wFz3nOc/DLv/zLAIDLLrsMF198MV796ldjdXUVF1xwAXbv3n3sQqJzQzxc2cj708UXX4zf+73fw8te9jLccsstePrTn45er4eDBw/iy1/+Ms477zy88pWvxMTEBN7znvfg6quvxuLiIq688kps3boVc3NzuPXWWzE3N4f3vve9D3GPf8p5aHPRf7q58cYb3ROe8ASXpqk788wz3dve9rZjVoP7GY1G7rWvfa3btWuXS5LE7dixw73yla90S0tLx9U1Ho/dH/3RH7mtW7e6drvtnvKUp7jdu3e7qakp94d/+Ic/5p4JcWKuu+46d9ppp7kwDB0A9/nPf97t2rXLXX755bT8ysqKu/baa922bdtcr9dzV1xxhduzZw815Nx2223uhS98oZudnT22vq655ho3Ho+dc8dbp+4nyzL3ghe8wLXbbXfTTTedsn4LcbJY1qler0fLLywsuFe84hVux44dLo5jt2vXLnfdddcdm//3s7i46F72spe56elp1+123aWXXuq++tWvOgDu3e9+9yntkxAPho28Pznn3Pvf/3530UUXuV6v5zqdjjvnnHPcVVdd5W655Zbjyn3xi190l19+uZuZmXFJkridO3e6yy+//Lg1d3/9c3NzP5Y+/qwQOOfcQ3fNEQ+Gr3zlK7j44ovxkY98BL/927/9UDdHCCHEw5yPfvSj+J3f+R38x3/8B5761Kc+1M0RQvyUo4vGTwif/exnsXv3blxwwQXodDq49dZb8ba3vQ1TU1P41re+JW2nEEKI4/jYxz6G/fv347zzzkMYhvjqV7+Kd77znXjSk550TH8rhBCnEuVo/IQwOTmJz3zmM/irv/orrK2tYfPmzfjVX/1VvPWtb9UlQwghhEe/38cNN9yAN7/5zRgMBtixYweuueYavPnNb36omyaE+BlBf9EQQgghhBBCNI60E0IIIYQQQojG0UVDCCGEEEII0Ti6aAghhBBCCCEaRxcNIYQQQgghRONs2Dp16JbP0njlai8WBgEtm8QJjRdl4ddbVbTsYDCk8Tv+524v9p3v3UnLBjH/uvmLLrrIi51x+k5aNokiGq9IXzoJ73en5bcjMcoG1re4knaMypIWvXf/IRr/7Odu9mJ33snHrj/RpfGLnnyBF3vKk59My27aNE3jUehPx6rmrgJjiiEi4xQZz6p95uN4JSfBfbX/vC1Co80WAfU0+OsNAGA5HUjx0Fj2gfF7BzabKvDOVODtYPuE1WTHnrnVbSNesbqNwmY7yA8sc4bl1DgZ08bJeTnMljzoun9u8+RJtMPm/33Lq2icfSO1tUarmu9lJdnjsizjZQu+RmsySax2sL0aAAKyqOuAj3VR8jOtIH3JjT08Ip+3qdehZdsxX+dh7fdx7wF+Nty3bz+Nn75zixc7bdsMLbttks+niMzVpbUVWjY39huXtrxY5Yy9yYjnZFug+weA//v1f8d/cBJ8/V//F41PTvr2yCjkDamN9yN2MCbGPFgfjmh8dcV/BsPhgJZl6xAAxmN/LXa6PVq20+XzIyTvA4ExD1otsgaM5724ME/jdeX3pUXmFwDExnsaM4BWxjtCUfCxc87fH5eX1mjZm2/+3zT+6Eft8mKPecwjadktm2dpvK79hbFC5gYA/OLv/D80fj/6i4YQQgghhBCicXTREEIIIYQQQjSOLhpCCCGEEEKIxtFFQwghhBBCCNE4G04GX1nlSSAsGchKPLQSnWnSpVHHaDymcZZQXhoJU2uDZRr/3ve/58XShA/RzPQUjUckGWuQ57RsQeKplQxuZT/HfmLf/MoqLXr33X7C/NH4PV5sbY3X0evw5CiWcDnO+LNiiWIAEEd+8hFLSAJ4QikAuGjDU7oREhhJeSTRMTAymgOzDpJE5nhiWVnxOeZKP16BJ7bCikd+ol0U8gRU83cXZP46I2nWkYS/k0t95j9gSXYAYPgGEJDk8dr6xCbyuI1Ex5PCSIA8uQY2AxMzAECr5e9xXUMyYcoxAr/upaUlWnZtlSdSFiURmRjGhqTN10ZN5oiVfB4Y8z1N/L5MGImzLbLft4yzoTISdddHfhJwaCQdb5rmibozfX/9T3YskYnRPnI+h47vhVHN41Xmj3UU8oR+a30VY3+cxoVhmWgAtq8AQETalxoCnSDhfWHnonlWGseOm/DbZ63DIudzPQz8Nddp8zPDkgex5GzjdQAVSRyPI97mVmKs5cCvwxr/ttGXfr/vxVzAG20lg4+G/vvRUs3fxyb7fH2etn0HKTtBy5KtFADgyPpMEmtt/Wj0Fw0hhBBCCCFE4+iiIYQQQgghhGgcXTSEEEIIIYQQjaOLhhBCCCGEEKJxNpw5OyIJZACQk4Rm69sio4jfa1hin5XAZCV4s0SvvOAJsksLCzRekG+W3TTFk75DnEHjkyQZqM54O7LQH9PIysyxEv5IfM9+/m2ut9/+fRq/7757vZgzku82TfHko5KM9fr6Oi0bk8QtAIhJIrf1hcYJSYoEgJgkb1nf4snTLU+O1PG5DpLgHYAnwYfgaytw/rexVkZSWJ3xRNjxmEgcHE8Kc0Y87Wz1YklnJy0bk8RxACgD/3nVRuKyI4nL1rctW7nP9MvFjcLWb1to8vhJfrs4LX2yme2kEutb3O2U7x9/MnhsrNFW2xdK9Cf9fRMAkpQnboZkvx+P+Tqy5BMI/YG1Epcj45vBwc46Ixk8NfIoU3Iu9rtcupGSby7PR7x/7GwGgPHY31dSI7l4+yzf76d7fvu6JKkdAALr263JIo2MxFnneF9Q+PtsbQhBSkMGMVr3583K0Pi8JrDeYcjXkcdk3wSA2PgGe/YeZEkBKjJ2R2vwx6kV8/kY1HxMo8Af09poR5nzOEuWdpWROE6S99PEaLP1peo1qdsoG4GPfycl55/xll2nfK6XGfuqel7Hlk2bafz0nad7sSnyzfMAUBvfXM5kAa30gcl29BcNIYQQQgghROPooiGEEEIIIYRoHF00hBBCCCGEEI2ji4YQQgghhBCicXTREEIIIYQQQjTOSaSQG3oXclexDCyFYTlggqnEMFiEIc/2Z18JHxr3qNFgSONDYkm6b88eWrZjWEgiYoGqDPtHlvlmButr6euKGwpq8nn3EIsUAOwx+rK4tOzFWi1uaqpq3g5mDhuPxrTsWrBG4wmxUUWGQaQyTFJx7M+xkNjEmqKNQ8ZPiNHGcSuOq30LDAAE8I1RQcWtU3k+x1sx8uNVze1SVcU9XCH89hnTA8C0EffXZ2VsP47Mg6A2tipDvsJmKTNRAdxyZZU35Fem0YqWNzZIa99kW29g1mGYvCw91ykkNgwlMZk8kTGhMmPvZHv1aMz3m9oaWLJ3BobNpzbijuyHoWGu6hnWxT4xPrVDwxRU+oaY9SHfVzJj/w1Kf0wnOtzQM9nr0ngS+30pjTMqMew6UUwsS6kxT61nWPnjMS552XHJ614mc2lp7dSdGaUxT0vyTpEbFkqjK8iJ4XJhkVs2l5aIkRBASfbDJDGsa8ZzWVn26x4Y5lJmkLOrNmxPbX+exrGlezL2arIfWHVkQz4/mCUsMfbB0NhTyjGxQBEjGQBs27yFxqcnfVtcKzHeIY2DkSxxZNYBeAL0Fw0hhBBCCCFE4+iiIYQQQgghhGgcXTSEEEIIIYQQjaOLhhBCCCGEEKJxdNEQQgghhBBCNM6GrVNJ0uYVRL6NoG75hpkfBTMWxbGhkzGoK7/81plZWnbuyDyNz8/58YMHDtKyacotDGNilEgM28jhw76xaHlpiZYtcmIiANDu+LaF+VVuJlpd4fGi8Oue7HMDUb/fp/FJYjkIjX5blomIGMVSwy4VMVUZABALTFly20ITJMF3+Q8c+czaMpkYNqrKt6O50jekAEBQcLNIkPnzqSBrBQDy0rAERb51qkq4OSWKN/N4OOW3LeJzyUX+XKoCbr9xhoUOxP5hmpqoowoISNhyNwXOmOvUOsXte860I5G4VdayS9H4qTVR5cRuBAD5qr/fLA64Aac2TIUVMbNYVsPaMLYwK1ZsWH5ahm2lhm+Hihxf5y3D2BcXfjwb87IFeY6hcRZNpHx99eGvxZAYd47+gIcdOXdci5urLGFcnft7SGnM39xYX0Xgnw+HlrlV8uCqYecqiCnSnYSQ8yTpdoz3I/LIR+u8L2PD4LS+7hsdFxf5O8XagM/TgpyXlo3NmjfMFleS9wwAiI262XjUxhqqC/LeFRtqRGPvZH0x+zfk519V+ntQu8vXRWyYvFZX/DOexQBuW7WwxtmF1vuRP06BscZPhP6iIYQQQgghhGgcXTSEEEIIIYQQjaOLhhBCCCGEEKJxdNEQQgghhBBCNM6GM55aKU8GD0kyJosBQBgZHxduPAmndn7yHQDU5KvpZ2dmaNnZqU00ThOvjK+rn5/jCVbra36SVm0kfx6Zn/PbMOBJP1byM0sGXzcSlcYZT8aa2eSPR7c7Qctaz7as/T6mLT5n+lPTNN4h5UMjORNWnOCM8W+C0drt/AdkPMqSPxczzhLqcp4EOBryeTMe+fGCrBUAKI0xjUmCZkqSYAEgio2k9Gjai4XpVlo2bJ3mt8HI60PIk+EcSQa38qTNVDgyHrWRQF1budmkcmeMvzlPyWNxrGIAzmzIQ5AMTuYvABS1P3fGFS8bGsmfIUlYrQ3pQ2j8Pi2N/cTGDkmABIBOxec74Le7Dg1xh7FlpSTRPDdmpSPPzPJiBMZeHZC1AeO8tdZM3PbPnbDDz4zAmNcJeS7pJD+zl1b9JGcAWB748YMrPMn50CIXDkxOTnuxid7JCW1OhnbKNzMmLRgNeDK4JXZZJeO0uszPhoHxPjDO/LleG+siMhKMI/KuFxnnSxDy98Ka7HF1ZUgSSJuD2hLGWO8DTLphFDXWRUZkQHGLP+/EeKdeH/rzd2WFz/9tbZ6cXZb+s61q69wxTkCSNG897xOhv2gIIYQQQgghGkcXDSGEEEIIIUTj6KIhhBBCCCGEaBxdNIQQQgghhBCNo4uGEEIIIYQQonE2bJ2KU57dHkZ+Rn1CYgAQWuoYmsHPM+HLmttJEPuV1FYdhrmqIGaRFWaiAjAquI4gbfvtS9v8q+ZLR+55ES9r2W6WVvz2LRuGjrUR70sUb/y+WZV87EYj34aUF/xZRQnvY3diikQNvYNhMrEkEaeKQ/v/h8ZLMk7ZiNtQxiPDEkbsEywGAM6wcdTE2pN2uVGl1eMWjKjwDWtBztsRx0doPIx6XizpnknLpn1iuTKMJWHI95Qg9PcrZuw5Cjdp1MTEY61Dq+6KVO2Mfak2tVj+rDa9KaFhKyJmESIVaZQi51abyvlxV/H5FBhjFRNTUxgYZY3fp02QOdU1RrZlrK+QGVsiXjaybIzU3EiL0vlXMYsUftRe6LePmqgAIDbaTPbwMOH7R0AsYwAQk04mhqFnfp2P6f5lf2+aW+VzaX3M27Fls9+Xmek+LdsEjtilAKAu/bmXj/kZmo14vCrInlXyyVTmfEwzYourDPtbK+VneYu8L1rzPzbeB9jZVZO9AwAcme0BsZkCtnSqrsgPjE3S2sMH674NbGjY9xLD0laQZuQZn9Nbtk7TeF7472PDoTEexvpkG4j1vE+E/qIhhBBCCCGEaBxdNIQQQgghhBCNo4uGEEIIIYQQonF00RBCCCGEEEI0ji4aQgghhBBCiMbZsHWq3ebWqYBYXyLDOhWExscRW4hpZjHsB8yOMSi5zWdlNKDxtbGf2R+Whl3KsJC0iIWkw8wkACpiEHExz+ovCl7Hyvq6F1syTFnDsW8iAIBWy38u3Q43iFjjPyZ17923j5YNAj6XImItmZmZoWVhzQOmSiD2oKb4n9sP0HhJDCKjIZ+PI8MkNSblxyNu3QgtKxPpe2+SWzAmJnnd3bb/bDvtZVo2Tfm8SVtdvx1TfG0xQ1Uc8b3D+k1J6Pw+1sYYWdapiNQeGmUtO1rMLEGGDcW0XxGTVGh8Xl0bViwyD5ippUkCYvEDgJTs7V1jjcbG3hnDr7vb43tnx7DatCP2fPmYlJaqhllpDINTaJx/LB4Ri+LRwn7dtWEqdIaRjdXhiNkMsA09EXkuUc33j9iwGmZkehwmFkUAuPvwAo3fsWe/FwvI3ACAftffVwCg2/XtPyzWFCWzG4HvIEnCn2HH6EsQ+HOpMOxSRhgD8h5UFPzZmiYpYhitjH6b40H268iwoNXkfcyS+LF6AaDVYqYsw9hV8fHIMv+sLI13xcIwSY2Jdioklj0AmNkyS+Otjt+XvODvvXnG30tS8gx7ETdWngj9RUMIIYQQQgjROLpoCCGEEEIIIRpHFw0hhBBCCCFE4+iiIYQQQgghhGicDSeDd3p+MudRyF3FSIYzvs2dlzcSdqyktYQk8qyXPGHnyND/mngAWMj9xOp+3Kdla8f7WIz8xJ/ltSValiV6WUm9ufEt8YPST3otjERRZyQjDnO/jtxIti6N5Mz1oZ8Edcddd9Oy9+0/ROP/F0liv/DCJ9OynZQnybHkrcBMvn3w/PctyzTOktPGOU+6KnI+TwtSvij5RDBy1hCRrncnuBRgYoInlfbafrzX5Qn9ExM8WWyi7/elrHkdadtPxIxiI3Ox9NcsANTxpBcLQiORLeD9pvIKY28DScIEeKJvEFhJunw8HNkTrKR0Z0wEKp44xcngXWNOJiRLs2083pbRn5QkhbY7/DmmqfF8STtqY38LKz5WARlXaw8PjMTZgMwpK5G1IudtaZyJpeNJto5U7sZ8b6oNgUibJH67gpddyvj+dmjJP4fv2neYlj0wz5PBmeAkjflajHgzMDe/4sVW17kwowlq6x2GzOmUvNcAdpJ+XfnPttXiZ0a7NOZ6uObFCpKgDABRyOuOiLyDCVIAoDLWVkwOL0uoUJF3PWucI2N9sn0iTQyRgTE9HJVD8LJlzceuIGurQ85gAJic5u+nLGm+qi1Jxan/e4P+oiGEEEIIIYRoHF00hBBCCCGEEI2ji4YQQgghhBCicXTREEIIIYQQQjSOLhpCCCGEEEKIxtmwdard5sYWltdfW9Yj0zpFYqFh+SBWBQAIiMFpWPCs/tURN2zklW9FmJzy7TUAEBvmgvU134KzvLhIy3a7/ph2J6Zo2U7XN/EAABJiSpjk/R4O+FfQLywe8WLLQz5GB4/M0biDb7C4/fbbeTvyb9L4N2+7w4tlFVeFnP/4x9D4ltkZLxYbhp4muPce39ABAI7Ya8qKP5fK6GNNrTGGfsxYL2Hot2OUc/vHaMjbsd72490OLzs15nXnla/piE2Thr8uWqmhJcr5+Aexv17CwLBOhYaViJmkDGNUEFomKRI37FKhYb+qyWc6o2xlGERcQAxLlg5losfjJ8km4/nGxLZiGXA6xq/CWonf9tgw0QWtNo3XxGBjiGqQGgZDts4Dw9hnzGBU5EMtEw87o0ZG20rDkBaSMyMg9kIAQJ3R8DjzH0w+9q2BAHDfEW5d3HvEN0kdOLJMy66PjfEnsWHG98j1EY/Pr/hnnbPWRgNYRrGYvMMkEV9DhlAMw6H/HJndEgA6Hb4fxuQzy4LPx7FxHoVs7zQabdmhmEHPeiol2T8C4/PimI9HmvhtbrV42dpY48w6xQxQAFBYhrvYb3enx9vRNuyPbF/qGs87jQxTIXl/Lox36hOhv2gIIYQQQgghGkcXDSGEEEIIIUTj6KIhhBBCCCGEaBxdNIQQQgghhBCNo4uGEEIIIYQQonE2bJ2qDGcGvakY15fA/gGpw7BLGXWwbP9sxE0adcYNFp3Yty30U24sAbF/AEBB4v2YD/Omvm+Y6kz0admxoarIif2gznjbMsNOkpd++Xx1lZfNuY1qfsk3iywtciPQ6vqIxtfHvtFg8ubP0bKWDSIi5oiZKcPY1QCrq3w8GC7gzyUIjLUV+c88jCzrkaHLIXVXFbdgZNnGbXE5MQcBABI+HkHHb8dEZsyxzLfRVGRuAIAL/bIAEBCTlINhEGGGFADO+eNUkxgAhIa5KmTWGMtc5XjckfbVxtbNDFUAUBPTlTOsRJh4BI+fJFsmuOUkJPa1OOdzrwW+h7dCfy3VZP8GgDrl7Qi6ZK8lJioACHK+Z5WZHy8N+1KZ8/03I5aksXG+ZAWxyBn7PcheCACtnr+gk5Sfq2GbG8hWyHqcW+FWwzvu20/jSyv+OCWGEaid8vlRjv3xmF/3zY8AsLhsPENiLKpqY0wbIC/5XtYmG20S8jUaRTzO3oNY7Gict68mxrPcMBU6470kJe9NgbFnjTO+xgcD/yxZX7PeKfxn3mtzI9PmaW72nOz7+wTrBwCUxrtUSExZkTHQgXGGTvW7XuyM07fTshH1rvFx6nYtg5llofTXZzbia+gsGv3/0V80hBBCCCGEEI2ji4YQQgghhBCicXTREEIIIYQQQjSOLhpCCCGEEEKIxtlwMnie84QdBH4ySmBcXyIjKTog2eBW4pAJyYkxvoEeYcUTmDqhn4jmjESl2EjC6aV+Ha1okpZtk2S9yhjnsREvSTOGA54Mt2YkeI/HfmJTTRI2ATvBfp0kbhUFT5ga53zsimW/3f/9ndto2Uc98mwa37p51otN9U9dMrglLXBkfhi5d/Z6Sf2EvxaJAYCRMwiSm4aQ2hf4OgT4HCtZEMAw54ntLZIIm+UZLVvkfhJaVRptDnkCKut4bfxepTISGuua1EFiR9thJYP7a5wlmR+t3GiHI+2wEjkdb0cV+EmNNYx27Houj58ktdlIf2+pa0OqkBjj3fITPcMJvs+Gk5t5vOsnhVptzlZ92QUAZOR8yApDXMAfL8K2P0fS2hAGkPxW1+Vrbmicc0tk7S6TvRcAltZ4fFgQgYiRMIwWT6idJI8rG/A9YUTOFwA4vOQnp66NDVGLsWdVZPicsc6bYGgk1MbkLOm3+dllJYMH5DCxksEr1nEABREOFIbIoCKJ4wCQEVmAlXy+usLn2PzCohdbWVmhZfPMnzfFFN8Ppia44IAmchvjbBEEZM0RYQ8AdMi7IgDMbvL3pS0z07SsM5LSS/LuVRjCDevNpCJJ4tY73YnQXzSEEEIIIYQQjaOLhhBCCCGEEKJxdNEQQgghhBBCNI4uGkIIIYQQQojG0UVDCCGEEEII0TgbVjtlhvWoqEgWemCYZ1o8yz6K/bj1te0lrxpFTkwfhuUgiXg7mNDHyuqPUz50HWI4qoy+DMa+KWGYcyNFaZgLHDHV5ENu4hmt87gjVdeGAadihQEUJTHJGJqVMjDMOMSScuDQPC37/TvuofFdZ5zhxU7bsY2W9d0OJ09/U5fG65oYG0rD3GYZzHr+hOx0+LyLDaMbixtCMdSmlcX/BwUMC4nxzIvC/52GJbCoSDucMe/CkMeZLMTYOhBaciRiEKkNRZgDt+WAGKZqw9RSGZtbTewfzniIZcXbV1SkHafQrAMYBhYAAbG7hMb8dQnfq4vUNxkFLb4Wg7RD43ngj0lZ8TU6Kozzj0zi0ng2ccwNNlHixyNiQASAisynquSWpaVFbvO59+CCF1s17FLrhiGpRc7sODIMYYaxiJmkFhbWaNn5NV7H6sDve2aso8KwLDnjbD1VrA/5WAdkn02NeRAFPM7MSZZ1KifmMAAYM5Naxud0EPL44pJvaYuIgQ8ADhw6TOOHSXxszMeE7BPtDl/31r4UkvnLznEAGBvGxJqoTmvybgQA08QuBQDbN2/yYlM93pfaaEdAzkvLGGWIM6lxq9Phe+yJ0F80hBBCCCGEEI2ji4YQQgghhBCicXTREEIIIYQQQjSOLhpCCCGEEEKIxtFFQwghhBBCCNE4G7ZOWQwHvslolBmmig63bkxM+Nn3bV8qAgDIDFPC2rpvq6gMY1S7xa1HPWIp6HdbRlkeT4hZZGiYElbG/thFMVcAbJ2cofHV9aEXW1rl98fYqDsltpbRkFtW8oIbFOraN1uQEADAEBNRO9e60Y7b7riTxs88fbsX23XG6bTsjkfxdpwM7W6PxpkpKMz5/A8CPqe7PX+O9Sf53G0TCwwApKkfzzNuWbHi49y3w8AwV1kGl4xUYWwTYIIfMpwAAEO+goiopALDvmIREh1HHfA62PwHAAdiISFmkqMYcUcGxPG9zRlGqzpnRhWjGQ3hYuP3WJV/7DjHN/wxMUMBgAMxFRqmPMeMhACGI//MyDN/PwWAgpwvABCSSRwaFrkwMmw3xJhTxfx8GZd+HQtD3r+9i7zN/7Nnnx80rG5twxRJTXmGRW5lmdsOF5Z8+9KBOW5kGhj7TRH641RYVjdjE7GsTKcKZrMDgMHY3ySTmI9dOzVsh3TP4p+3PjTeS8g7HT0DACSJZZLa78UsY9FwwJ852ycT472r1+t7MctkFxj70vrIX/vLa749CwDm5+dofDjy+xIFvB0z09M0vnnTrBdLDWNXkfFFx+x5zthLW4bZr01ewgMuvzoh+ouGEEIIIYQQonF00RBCCCGEEEI0ji4aQgghhBBCiMbRRUMIIYQQQgjROBtOBu/0JmicJRQNFnkCzf79izS+adZPPpqemqZlk4Qnw1aZ/1XsvYTfo3ptXkdEkqbCkCfKBEYiZUS+Er5T84SdrSTR3BlJP7GRHb++yhL+eONaRiJVZ2bai4UDnhQZDngCWUES2aqcJ9/VlTF4J5GTd/AwT8a67fa7vdiWLdto2Que8asb/0CDOObJ4CVJ8I5rnowVhXw8Jnr+M5+Z4vOgnRpJ4iQZfDTmmZVjIx4P/XbXQyOj35jr2cAfjxHPc0Q29usuCyPRN+VrPABZy0bSp5kLGvh1hyH/PCMPmQoRHJ8GJjXZpmvjV0TOWEQ1WYqV0eamKEK+l+Vkuruaz71sZMynIbML8HVUpnwvW1739zJX+vs3APQiPq7d2I9ba7FI+P6bk/ig4pPk8Krf79vuPEDLHjp4mMZH634fz9i5mZY9+xF879x730Evtn8v35P3HeFJ6fNLfl9WyTkOADDO4YSIXSzZQm0s9ICc+6dyaaTG/ACR1xSVIX0g7xkAUJGk/rFRdmllmcZZ+V6fn3ObNvkiHwCYIO8aLUPCUxl9TNtEGkH2ZABodfz2GVs1ooSvrZLsQVYS/Ljgcfare2vs+n3+Tt1u+RnXgSEhsQQHBTGqRIZg4mTm+gMVJ+gvGkIIIYQQQojG0UVDCCGEEEII0Ti6aAghhBBCCCEaRxcNIYQQQgghROPooiGEEEIIIYRonA1bp2BkvbfafiZ7r8uz7FdXVmh8sOrrZ0rDWNRKuXWHNe+MnTtp2fHYz8gHgH37fUvH0or/lfIAMDYsJD0ix2gZZcvMNxcwIwsAOMMItEasU9nYMFKUhpUl88cjifgdNOwaRhXSx0HFx66seTtCMkyBYZkYDvkzvHPPfV7MGFL83h8YPzgJYmJ1AoDYEVOQYUFLEz4/NhHDFIsBQMus24+nKfdMpC3jmcf+CAYxX59lzusuiVElMp5tTcwplWEqqwx1UsmaxxRQAGpneDfohDTqMOtmZXlf7LhfiVEUlTPGlPxOqT6lbh0gs0xcRAdTxXxerxbcGLU68o1RdWHsNwGvY33ol7fWUW8zt+uExK4TxNxqMzTmyPrYn6x7Dy3Qsvcd8OP77uV2qRh8jZ61yzdJzfa7tGyacyPQ4oJ/Zu85xMd/ecDPLhYuDH1bxNYiAOf89hGJFAAgjvkPgsDfq0/lymi1fasQALjCnzeW5Kes+Jgy65xlnVpdX6XxIPR7Pzu7lZY968wdNN4j7wmkWgDA1FSfxgfEaFoZe3UU+59XGjarDrE5AkDS8s/ysjZsZ8a5H0V+O2a3zNKyvQne7yAglseKv+9YfSwLsi4M6yizrgFARVSFVcnn3YnQXzSEEEIIIYQQjaOLhhBCCCGEEKJxdNEQQgghhBBCNI4uGkIIIYQQQojG2XAyeJ7zhDqWYDVpJPfUtZ+EBgDjzE9WqivrK9d5FmSS+kk4m2Z5Es7U4jKN373PT6pbXfOT3gCgZaQY510/kWeywxOH5lb95LkhScwGgCDlCWQtknh/epd/tX1hJb2SBKaSJOQCwPqIj8dy5ScODUhiGgAERpIiwJMoGZWRWHl4ftGLrQ/53G2Cdoe3IyIJVqmR8Npt837PzvrzZtM0X7KR40laYeCvrchIikzaVtxvX6vHpQBlYSSWFf7vNPp93pc48edH7XhCY1HysWMJbtae4sxkcBI3E+eMRG7ykSVZK4C9t5WlX0lplTWSF8vKf1612/h6eyCURiKxYwnrhhjA2hPq2i9fGHmKpZHAH5Gk9JaR5Nnu8v03JOdOZsynw0tchnJgzt+z7r2PJ3gfOeKXzUe849uNBPZdO/3E3trYI+cOzhvt8CUkc4t8jZZGFnBNnnkUGXPSWHeOLLDQ+LwwNOq21v8pIo35HHMkBd3IgacJ7AAQhv6+EEW8f22S/AwAvQn//WHHDv7uZsVnp/06nPFOMd7M515J9uvQGLsg8sejNBKXnZFIz3ag4cCQ3+S+yAcAOmSf2LZlCy3bbvP3AZbgnRFx0NG4seaIfMU6X6y9NyRrLjfOrhOhv2gIIYQQQgghGkcXDSGEEEIIIUTj6KIhhBBCCCGEaBxdNIQQQgghhBCNo4uGEEIIIYQQonE2bJ0aDLkxI4p8C0Cnw6vtdrfTeJb5GfJFzrPby9Kyu/iGArewQMsOSl738sjP7F8Z86z+1DAnFfDHIzeuc4dWfYPT6oh/XneSGzOeeO7jvNj2bTto2U6Lm1PGY990Nbe0RMveu/8+Gl9e8sea2RMAwBD0ULGII88VAGpi6ACA8dg3SmS5b/dqim6bP9wo8uNtYqgBgJ5hJZuY8NdRr8M/rzbWhSOmCdNkUhu2ltivI2nxsoFhjWHhKOZ9qYjZIjMMRjGxrBzFr9sZ/TNkVCdlnaqNSV2R+WtIT1BVRvsqfx5UtWFjCnwLHQAEiW8CDAM+75oiNPayMPT7k8R8bTCbDABE7a4XGxN7HgCUMa8jjfyx6hgGuG6LG2JGZN0trXNDzB33HOTxu+7xYosLq7RsTSbP5s0ztOzsLLc/Tk/6Y7eX2KwA4I479tL4obmRFxsalp804eOfEBtSSM5PADCWLiUwzgZm0QGAmpir2PtEUwRG3RGZ67FhygqJMQ0A6ppYBiP+eTMzkzTe7fnxzTPcYNZp8+eVJH67K0ML12kZ84Ocl23DqBknLS82NgyeKyv8XbZg9lNjX7feS1otv81p6rcN4OccAORknIqC7ylWHcywxkxUAFDkfJ9OEtYXvseeCP1FQwghhBBCCNE4umgIIYQQQgghGkcXDSGEEEIIIUTj6KIhhBBCCCGEaBxdNIQQQgghhBCNs2Hr1GjMzT3MlJDG3G7UJqYQAJjs+yaBJOF1WEaJgth17tq/j5adX+XWgfsOHvBioxHP1E+NK9p65lsYhjm3DhwmdhJDtoXYMKqkE74hYufpZ9KyZ24/jdeR+G3+/h2307Kra9xGVRW+4aEwTEFE8gEAiIiFBI5bN4xpABDbgmP2oIawrBvMCpLGvGxMzG1H4/4zjwyrU23YJyrnP4MxsbwBwPqQW0GymlgwjM9zlgSKGJUy49EOhn4lcWTYNQJjIVJhlDUPeNw5UrfjZUvLGEUGpKp4x5ld6mg7/H0ziLh9JUk30XjUmvXriLlJqSm2bd1J4wFZo6Fhlxobe0iXGALHtWEqBJ+UceTHc0MJNn+AW5n2L/p2qHsP87IH5+ZofIEYpnKj32y+j40zamlxmcb3ElPbvkNHaNl9y2s0PiJDHcfGgraWKNmXY2MtpimfHy2y/2bEogjY5rqE2O+YGa0pQqOPMVkDiWFMs2xIZekbhJwx/zdv5nvFRN83TPW73GaXxMbeWftjXRfcbkTPfQAd8sx7Xb5npakft479wRqfp2NiI7XmjGV7isnzss6dPOfzNM/9va0m5/iPgrWjLHgd47FvkAP4O0y7/cDODP1FQwghhBBCCNE4umgIIYQQQgghGkcXDSGEEEIIIUTj6KIhhBBCCCGEaJyNZzwZX7nOklBL8CSXorDuNX6yTEWSuwEgNpJhI/I17zu2b6VlzzidJ0W32n4dw5HRl4qPxzgnCYY5T6QfZH4d45InI44P8GS9z//vL3mxe+66h5Y99xFn0fjjHn2uF5uZnaZlf+EpF9H41OyMF9t9yy207N69+2l8fZ0kJZHEUcBO9KJ5dsbcbQKWSA8AEUkmTGMuQ2CJbFYdNUtQBpDlfN4MB34C3vzikJadW+KJnzlJPKycYS0w2heQRzDR4c82G/n9LnI+zlXN6yhIwnUYntw8YInctWEyyA2LQ0YSDKuCb7ukKACg1fKlAJ0eT+Ts9fje1pn0E7PjNk/wbApnJIrSX28ZJ1FiJOX2An8txWM/qRoACiPpsiSbRWbs94fnuEDk7r2HvNj39nAJychIUs6JSCMn58hR/DZb52pY8rmakIT3lTW+J9RGIjFLUk6Nx231JE38Oia7XALT63ChygRJBl9eHdCya0Pex03Tvlih1+btaAKWqAsASUKEL0bS92jE+7JKRDdl6ScXA8CWrXyv6Hb6ftusNltrnJwPJLf4aB2GCILFI2MLr8h7U2kkckdGQ2oikyiN9zHrGXbJ/LXKZhlPji9LkkhvnLftNpcEhSTBvjCSwa2k9JjIayKjLydCf9EQQgghhBBCNI4uGkIIIYQQQojG0UVDCCGEEEII0Ti6aAghhBBCCCEaRxcNIYQQQgghRONsOIU8Mew6DOsr1yuS1Q8Ade7bhoqQZ+Rb1qkEvh3AMiJMTfiWCQCYmZryYkTQcbR9Y96+ihgDRoZdICeamcL4vIyMEQAUGfm8ES+7srxI4wfnD3ixc885h5bdum07jT/uMY/xYoFhjPl27zYav/Me35a1vsb7EhqmCmadcoYpqAmSkNtQosiPd1rTtGy75Vs+ACAI/LleFNxCsrLG59jCvG+S2rOXj+m9exdovGDmE/NXFMZYkyqmJvgz3Drr25C2beEWmLzk+9JUztrBx84ySWWFH7fsUsMhN3cMhv5zKQzrVG7EN2/x96XtO/l4tDdtofHO5C6/bJ+bq5piJef2n4DMEUsiB8d/EpJ9MhtyM1Q+5tadMTn+Fge87KEFXveR+SUvNjfP7VdRzM8uZncJwA0xFbEdZmN+aKwaZ+hC4o/pyLBcWftsTOpIiekGABzZxwBgcsKfw6dv8+2FANBvczNfK/I3orahv5oY8k1rxw7fTjk9xffkJqB2KXCD59g4y9fW+BwbE7PZ5s2ztOzsDB/rOCZnmmFujAyTXxD4Yx0YqsiWYTIKSfmcvF8BgKOWUv55KTGUAkC/7++zhfV5NV9zEz1i7Er5GVUbRrG69udHZXxeaKm82PMy9lITUgWboxtBf9EQQgghhBBCNI4uGkIIIYQQQojG0UVDCCGEEEII0Ti6aAghhBBCCCEaRxcNIYQQQgghRONs2DrVanVpvGap6YZ4JjRsVCz73jRUOR6vAv9Dy5JbNwLDPtMhdoCJDjcUjKjlAMgKYingReFqfzycYXeA43dCR8wKwxHv931HDtL43iP7vdiBQ4dp2XMf+UgaP+ds31K1c8cOWnZtndtolkl8NPLbBtiWmpqMn2WIaILYuKozY4b1DMuKxysiwLFMFQtLfF0cmvfn46E5bkg6dITHS+d/JpGK/B94OwLyXPIRt3GEZJyYxQQAgojXMRz5bS5LPg+ynMdHIz++PuJjNCZlAWAw8se/KnhfipLbeVaH014sB7fOxH0+/tM7/f27HfuWlSaZH3BjTjb01/n6yjKvxHhmETkHioyXzQ1TW0YsLCvE4gcAC6vrNM5Ge5Nh8+kaZ0mr5VtmQmPPcsT6UhnGKBh7RUFsasbQIav5XM2I/QqGXWpmkr87nLbVt56ds4tbDSPDmDMe+ptkGHFj1OQUN7Xt3OE/r5lTaJ2yLHdjYkdbW/OtgUfL8jM+Je8wp522k5btdieN9pGYZRsK+Byj71iVYZAzzEmOvEg6Y06D2McCEgOA0LBcdbv+PK0qvkdWxrslqyM0zq7YaAfgG9acca46cjYDABtS4/UbkTFOETO8nqy56v72PKB/JYQQQgghhBA/Al00hBBCCCGEEI2ji4YQQgghhBCicXTREEIIIYQQQjTOhpPB49hPWAOAgH0FvZF1YnwDPc33s5LBzcxq0g6aqA6gKHhC52jgJ14FRtIPHw0gjPyEs8BI+slKP1mygPGV98bgxQFJhjUSdrIRH9MsG3qxby9/n5a9b98+Gr/jzju82KMe9RhadjjmfewkZOyMtG9nzA+aTG/OpQdPFPK+sHy/UcYT+ypjPEpSSZbzvhyeX6Hx+UU/8XY44uvCBTxZNSCJaHZKmJHESpIGK2OejkgfV9dIZjxA1z0ALC75dQ/WeR1rZtzfJ1gMAEoj0bEiw1Ebv99xtZEMPjrgxZYGfE+pW1tofGrHo71Y1ObzDnwanDTra3xOsmTYsNWjZcMJ3s848fe9asifTWAk8EelHw/ARRV1yOdIQM7FToc/X+Pkwijz2xGW/NmEJBnWElIkLT52rZY/z8bG59URr6NDzrR2i0+cM0/jyfFbt0x7sYkuryM3stUrNqpGcnEac3FEiyRQt0msKQYDPsfWVv31Mhz4ZzMAJAnfK7Zv9wUsO08/k5bNDfEBG+vaOm9PIkmZCXsAW9IRkn0ySXm/0zZJ9Df6lxnxgLy3djpcIDA9NU3jrdTfD1iS/4+i3faTwVleNgCMM153q8XmLx9/1m8ACMmHWkKnE6G/aAghhBBCCCEaRxcNIYQQQgghROPooiGEEEIIIYRoHF00hBBCCCGEEI2ji4YQQgghhBCicTZsnbI0MzWz/Bhfi+4CnjofhH48Mj6vMr9H3Q/FRiVTE9wkcPaZ27xYEnELhst4X0ZrvtHg8PwiLVvPH/Ji1XCdl3Xc7hAx607F7QIw6ojJNAiMsbPsH/sOzXmxZcMCkxvmpPV137BRFoYZx5gHzDTGLDdNEQaGDYU8g+GYW6eGmW8fA4D1oV/3ujGmyyu87qUVYp0a8zYHxnYQBf7vI6LIso3wdVERW471VCryvPKS7ymjEe/LiOxLS0vc0LG0zC0wSyu+cW7FsF9ZY4fAj6eGMSZNeB3ra+TZxkdo2bkFfx0CwMrqqhfr9Hm/MTPF4yfJkXneljDyzSxhzPfkJOB+P2ZBXDNsgmsjvocM1v3+LyxzU9bBwzy+SoxW49zYE4x9qKr8tRQbZ2hCfjXYMexS3bbhRiRjGhtGpplNfC502/65ONWboGW3bZum8QlyDgeGMapyGzfzWftKZLzExGx/I7GmYFYhAFhbXfZiFdPWAej3uaVt2/btXoyZkABgbJwDFTNGkTkKALVlnSL7vWXDDEI+fx15L3RGHex8CQ1Tp2XsqkkfrfOsbdioEmbDqyzfnPFuw95h2Hs2bGNXm6z9NjNzwXyVos/cMlSdCP1FQwghhBBCCNE4umgIIYQQQgghGkcXDSGEEEIIIUTj6KIhhBBCCCGEaBxdNIQQQgghhBCNs2Hr1CoxdACAI9aBKLIy9bkpgSmtsowbRAaDJRqvct/WNFryTSsA0C2Xafzs7ZN+2f4sLbu6zO0z+0rftBIEvr0GANLYtxG0U25xKGpuF4gTYluwpFO8CgTEsGGJmpjlAwAqYkMajY1nZRgsisJvILNJALb9gIkmDFFFIwSBYVgjpokRMdQAwOIKH4/5Rd9GtbjEDVWjMa97SNaRMwxOoTFxUrJLsBgAlMbzGud+3UHAPy+I/PkYRvwDYyMOYulwjv9epch5PCvIvmSUjQxLW0jiSYsbfqb73ArS6vh1xBHff6qCW+sGA38vXFnlJiXgNCN+chycn6fxMCQmv7BLy0Yt3s8w9c09S0t8v1k2TFILi/6YzC/y8Vtc5OffOPfbVximoMCwHoVk/20ZFqgWMZONO/zzDEEgKrIhTk/y8d++jcc3TfqGqekJbp3qdLi5ke0UqyN+VlrGLpCxC42zITKsl+yAqPmW3AjtFrdOMVOTIRtCmvIx7XX955Ub5kbL6MgsSZXRECtO+2LYl+KY7+HsvcQ6X1zun3ORsYbabR5n0rqi4PPRcpux4WjCeumMcTbfg4ixKzGshlbdNRlrWaeEEEIIIYQQDxt00RBCCCGEEEI0ji4aQgghhBBCiMbRRUMIIYQQQgjROBtOBj9kJPY5ktLVMb7qfEvKk8GThCRjGcnP+Zgn6xVrfhK2W/ZjANDNeJL49r6fQDNzBk8GX+wbSbn50IutDvgw17E/Hl3/nx+tY8yTEcuKJHRZ33jPMqUBBIl/33TgiXNGLhbywk8oyjI+RmW18cQyKxkuMvrC+hg9wASmjRAYg12RbEIrYXttlSecLS35z3xunifHWkn6bKxbRk5ku8XHqd/z/8HUBE+oG2W88uV1f2JbSYBx7NfBYgCQpLzNbN6Q3EIAgJGjiLL0685z/nlG3iEikgBs9XtiIqXxtE0SXlMj4dgQT+SZP5dGI76nNEXamabx8cjfs1ZW+J48GPNzZzj2+zk2sp/HGc/szTO/HbGxnk/b0qfxKJ7y64j5RIsNYQArnyZ8QqUkoTMh8gQAaLX4fOp1/WTklmF3sBJI26TuyCgbJbwdzAURhTxBOUn5eExMbHy/j0mCLACw42htaBzEDdBq8UTukmxEYcifbWLMj4wkRWcZ3xOGRuJ9TX7/HFrnrWFaYcdRRmQvANCOjM2TtKMwEthB+j3VN+Zul4//0Pn7RMXerwCMRvzdpk3efcdjQ2hhPNs49sfUSti21jg7L61Ebpb0bcWtNp8I/UVDCCGEEEII0Ti6aAghhBBCCCEaRxcNIYQQQgghROPooiGEEEIIIYRoHF00hBBCCCGEEI2zYevUwTlucGKWg15vgpZNOpM0PjNNzB2GwaKV8rtRmvrGABdwM0AYcwsAJn0bwfbTttCis9t4O9o93wLQ7/KyC0srXuzw3AIte+8BPv7La76Fqwa3rMQRt27ExCTA7Ak/iiExKywsc3OHIRSj9o8gMKaocUVmdozgAZoSNoILDOsUMViMDPvHwLD/jIgVJMu5BaM27B/O+X2PuKgCLcM6NTvrr4szTuMGueU1vrbcAX+cLINZi6z91LBLdYxpyiwdUWIozJj+BkBN6qgqw9xmmc1I3aFhH2p1jD2l649H1DL2wYSvfef8uVQVp86sAwCtFn84jhw7nZqPSWUYlUDi3a7REOOxkyVq7pHtlmFII8UDYz5ZsKnTMiY2s8wkRpstM1/A9gpTzMfHPySfWTvejpJPSTgyTtb4p7GxWRC9UcuwXFnxmMylB2rX2QiW5Wd6apMXK3t8v7fMdYsL/vuDtTcNhtyCCHLmhoaxyxnvGmwNOGMuZTl/IShDsncan+eIHSrP+fOuHe/3YOC/S1lmvrLkz2VMbHhlyfuXGia1gOoRrQXK42Xlj9PQMKlZ87EidZjn3AnQXzSEEEIIIYQQjaOLhhBCCCGEEKJxdNEQQgghhBBCNI4uGkIIIYQQQojG0UVDCCGEEEII0Tgbtk6tDrnB6cDBQ16sYPogAOOSmwvOe+yjvFjfsMl0OrzJndRXjkQ1ryTv8Wz/LZ1tXmxm1y5aNupw687ZZ5/pxc5/7Dm07Pe+8z0v9p9fv42W3bvHH2cASGrfrBAZVpvUiKPyLQzbjAcw0edql8L5ZoU793DL0sFFbibKc799cWxYT6wrMrFd1Ewv0xBlzesuiGliTAxtADAkpgoAGGd++dywTgF8bTHlThgY9jG+LNDv+2tu82bfRAUAQczHY2nJrzzLue2CPdvQMPnEho3GkfkYGoYwZqgCgIoYbSrDmGapjRyJlyUvW5a8fcwgEhqWJkfKAkBdMOsUn3dN0WrxOYLQn081iQFA3G7TeF74DyKithbA2vZAhpsZ+ACgY1inQOZUbewJzvHnyywzE31ubmRjGljmGTJGAJCN/X3F9mQZewWxHjETFQAUlbXu/Li1Fq0+RsSGZBmSIsvORWxUYbThV6OTpir4OTA54T9zS/JTGaagNWKhtJ6LaQMjs8HVvM21MafbxI4WGuuzyPg8LeCfddZaDsh+b83/0uj4cORbmXJrjzQeTJb5bXbGszLjxGxYs80K9l4TEZNaeZLvQex5PTDnlP6iIYQQQgghhDgF6KIhhBBCCCGEaBxdNIQQQgghhBCNo4uGEEIIIYQQonE2nPF01977aHxEEsvimCfwLa74iUoAsLi84sXSkH99fCfh6ShxSJLyEp5AE/V43f1NW/2yIe9LMeJJuauLS15s3547aNmDe+8l/36Of56RhTrK/MTqTosncsctnu1bkGTwMakXAGI+dGD5xUZOHk1UAqwkYF5HaCRtskS2miT1NkVW8ASrjCSiWYncLIEMAMakfGFm8BlJlAFJvDWGIzYy7eLU/wetDm9Ha8QrTxJ/MuSFkRRNEppZDABKKykapI6aj3NZ87VVkSRWS3RhNAN14LdjaOwdy8t8zXVI8XaHt2NqwOsuiFiAJYg3SRzzZHCWlBiVxp5Q8U2EJfwyAQAA5EbCZEnWrqVUgJFIGZI1Y+S8Ik35eHRIgvcESQwGgJgYG9aNZz4w9pURmX9sfQJAu23IV7p+m9OEl10fcJHMmLw7FAVvs5UMHpKk9NLYC4eGjCMlv2+NTt2RgSLj667X8c/tKOJn9mDoJy4DwMp4zYtVxtglxnysyX5Ykv0DsJPBO+RFITTELpmxD5VEqGKKbsj7QGFIN2rjHMjI/KjMZGv+XliSM8NKYK+Ns7wkSeLOEJlUFe9LnPrj4SyhiiELSIgQwajihOgvGkIIIYQQQojG0UVDCCGEEEII0Ti6aAghhBBCCCEaRxcNIYQQQgghROPooiGEEEIIIYRonA1bp9bWuTEqbXe9mDO0G3fcdTeNT3V9Q0E39g1QADAxa1hmiA2miA2HSMDVSSExXS0tDWjZJWLKAoAD+/0+3v3979GyR+YWvVhl2E02bd1E4+tuwYvlholgzbAcpGScBgW3TIxXuNmFGQ1qcGNGyoUNYA4MImA4WrbN6w6IjaY2xrQJVta4UWV1zX8GawNuFRqO+Fhnud/ugpg4ACBwfK4HxMJVlHzZlyVfWxW1QPF2lIbpg8XznD/cksxTQ1iCYZe3OSCWjpyMJwDkRpuLwq/D6ndtmF1q8lzWB/x5zxt97GZ++7pcLIeJKcPsNzfvxVxtOpYaITf2m4qYagJDZxIaa7cuiUXL2PfY/AWAMCDGKMOIZ9l1QmJ1i4gJCQBSw/rXImYnVxv778jfQwZrfF/Jcz5XY7InoOT9y8eGVY+pdGpuMbKMeCkZJ2a6AYDIiMepP6bOUhUaa5QNxymUTiGxDFpEB5iN+fvHYJ1bpyryHmRZ18bG/GCHbsS0kgC6bX6YJ+TZ1sY6jA2DJDOKWcbKmFnojHcHZ/x+nb1rOONZpSl/h2ylvi3OlXxfcsZZwoYjMsxQMGxxaeKvRWu7t/7aEJH3+MBYyydCf9EQQgghhBBCNI4uGkIIIYQQQojG0UVDCCGEEEII0Ti6aAghhBBCCCEaRxcNIYQQQgghRONs2Do1Gmf8B5Gf3V6V3IhwcN9hGt825Zurtk5zQ8f2TZtpPIh6XizszNKyw3WuIzhyaMmL7T10gJY9cPAQje8/cJ8XO7z/Llq2qvx2VLFhJulzzcxEMenFlpaXadlVYiwBgImOb47IS8PMYMyDkhhf4ha3kKRtbmxoE1PQaGRYlgyzWUwMWkHEx7QJDs+t0vhg4Ld7eZmP/+o6H9OMhMvCsD44Y5yINSMjFiMAGAy4FWRtzX+OK6v881aIbQsA1gbEwrXOxwNgti1u/4gSw1JDpsdgwNf9OOPxLPP7mOW8f1HM2xcT48vaqmG5yvj4d8l22ulxhUjc9vewo/F7vNjCvG+saxJrqlbErlMbZpzaMrNUvpXJGZoZy1jGDEds/zha1tpvSB0J328iw4ZUkb7nA26zY9Y5SwSTWnMy9NucF3xeZ8Z+zyw4AfjYWcaogAxTRkxvRwsbZiKyvyXG+LNnBQA1OYcty1gTtIz2pWScRqVx3hr2wZi8PzhjgozGfI6BrE9zTC0bEvlMZygkE6OOgHxmaBmqiEHOaltkmJoC+O9SWc7fYdqp/84KACmxTtWGwbMi5rz/8y+8SGKsZWf40SKy6TlLxmYQkTF9oH+Z0F80hBBCCCGEEI2ji4YQQgghhBCicXTREEIIIYQQQjSOLhpCCCGEEEKIxtlwMvjQ+Mr7wZqf0FnkPLEvHw5ofGF+zoutLG+lZctqB433utu9WBJO07IrK/7nAcB3brvTi/3Xf99By967nyeDr6z5faxrnriVJP49LzESpYMuT/rpTfoJTOtjI+l4jT9DFP7zSjee4wUAIPl0CAMjUSnhWUnpSSQuj41Etrj2x6/V4WPaBMMBT+gaDP1nPh7zhMs850lyJUmANvLp7AdD4lYiYVbw7SDLSVK08VxyK07qGBvJz44ktodGIu14bCS8kvlr5LuiLPmgVhVJWna8zais39mQ8ch52cqo2jm/4S7gnbHW+PKSnyRelsaANIQzEnjZGFalMReIZAIAgtpfd4khfQiNJOA08feFxCgbG0moEZlooSEoqIxzoCCSjtHI2KvJBjAx0adF26R/ABCR51Ku8fEvDPlBkfh9SRO+jtI2T6hl2al5xvttSQFismgmjfFPjXgdkcRlaz9tgFbKnwtL5A5IQu6PiqckgToi5yoA5MazZTIOK7HaSs6uyXOprWRwYzwithaNfrPjITYkBJ0u/7xWyy9fGIncETMZAAgjX6zjDMFEVRhnBtkfja7Y0oLwJOa0kSQekWdrzbsTob9oCCGEEEIIIRpHFw0hhBBCCCFE4+iiIYQQQgghhGgcXTSEEEIIIYQQjaOLhhBCCCGEEKJxAncq9QpCCCGEEEKIn0n0Fw0hhBBCCCFE4+iiIYQQQgghhGgcXTSEEEIIIYQQjaOLhhBCCCGEEKJxdNEQQgghhBBCNI4uGkIIIYQQQojG0UVDCCGEEEII0Ti6aAghhBBCCCEaRxcNIYQQQgghROP8f/UEF/O4XHPlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1000x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_images_to_show = 4\n",
    "fig, axs = plt.subplots(1, num_images_to_show, figsize=(10,10))\n",
    "np.vectorize(lambda ax:ax.axis('off'))(axs)\n",
    "\n",
    "for j in range(num_images_to_show):\n",
    "    axs[j].imshow(imshow(images[j]))\n",
    "    axs[j].set_title(classes[labels[j].item()])\n",
    "    \n",
    "plt.subplots_adjust(wspace=0.1, hspace = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd60cf5",
   "metadata": {},
   "source": [
    "#### Part 2: Defining the Convolutional Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412f2e00",
   "metadata": {},
   "source": [
    "Implement a CNN architecture as described below:\n",
    "\n",
    "- Use three convolutional layers, each with a filter size of 3x3. Make sure you preserve the spatial dimension after each convolutional operation. The first two convolutional opertation are followed by Max Pooling of (2x2) with a stride of 2. Please use ReLU as an activation funtion. \n",
    "- The number of channels of each output convolutional layer should gradually increase to 126 throught the training. \n",
    "- The final convolutional layer is followed by **global** average pooling\n",
    "- The resulting features is fed into a fully-connecetd layer which maps the features into 64 features (use a ReLU activation funtion and Dropout with a drop probability of 0.1)\n",
    "- The final 64 features are fed into the classifier\n",
    "\n",
    "**Note**: You need to keep track of the channels and spatial dimensions of the resulting outputs after each step, because you will need to define the dimension of the fully-connected layers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "200964cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):  \n",
    "    def __init__(self, increase_factor = 42):\n",
    "        super().__init__()\n",
    "        # define all the layer we need. They do not have to be in order here. \n",
    "        self.conv1 = nn.Conv2d(3, increase_factor, 3, 1)    # \n",
    "        self.conv2 = nn.Conv2d(increase_factor, increase_factor * 2, 3, 1)\n",
    "        self.conv3 = nn.Conv2d(increase_factor * 2, increase_factor * 3, 3, 1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc = nn.Linear(increase_factor * 3, 64)\n",
    "        self.classifier = nn.Linear(64, 10)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):   # (N, 3, 32, 32)\n",
    "        x = self.pool(F.relu(self.conv1(x)))   # (N, 42, 32, 32) --> pool --> (N, 42, 16, 16) \n",
    "        x = self.pool(F.relu(self.conv2(x)))   # (N, 84, 16, 16) --> pool --> (N, 42, 8, 8) \n",
    "        x = F.relu(self.conv3(x))              # (N, 126, 8, 8)\n",
    "        x = x.mean(dim = [-1, -2])             # (N, 126)\n",
    "        x = self.dropout(F.relu(self.fc(x)))   # (N, 64)\n",
    "        x = self.classifier(x)                 # (N, 10)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98f3f87",
   "metadata": {},
   "source": [
    "Create an instance of your model and run it with a random tensor to ensure there is no error. Also check that the output shape is (N, 10) where N is your batch size. **Note**: If you are using a GPU, make sure to move both your model AND input tensor to the GPU device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37e9a857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "model = CNN().to(device)\n",
    "random_input = torch.randn(1,3,32,32).to(device)\n",
    "print(model(random_input).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48377b41",
   "metadata": {},
   "source": [
    "Refer to the [torch.optim](https://pytorch.org/docs/stable/optim.html) library. Define the optimizer and learning rate. Use SGD with momentum, with an initial learning rate of 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b669fde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeae6771",
   "metadata": {},
   "source": [
    "Define the learning rate scheduler (use [cosine annealing](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.CosineAnnealingLR.html#torch.optim.lr_scheduler.CosineAnnealingLR)) and plot the learning rate variation for 100 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9520f5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "lrs = []\n",
    "for _ in range(epochs):\n",
    "    lrs.append(scheduler.get_last_lr())\n",
    "    scheduler.step()\n",
    "    \n",
    "plt.plot(lrs)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('learning rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba10cd0c",
   "metadata": {},
   "source": [
    "now define the loss funtion. We will use the [cross-entropy](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) loss (also see the input shapes that this loss expects to know how to call it later). Note that this loss applied Softmax on the class logits, and therefore you do not need to define the softmax. This loss is equivalent to applying [LogSoftmax](https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html#torch.nn.LogSoftmax) on an input, followed by [NLLLoss](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html#torch.nn.NLLLoss). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8107116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86fd4ee",
   "metadata": {},
   "source": [
    "Write the training loop funtion for one iteration.\n",
    "\n",
    "- Set the model to training mode (since we use dropout which has a different behaviour in training and testing)\n",
    "- Iterarate through your data loader. Zero-out accumulated gradients in the computation graph, run the inputs to your model and get the outputs, calculate the loss, backpropogate the loss to calculate gradients, and then update the weights\n",
    "- Your training funtion should return the averaged loss and accuracy at the epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029c7ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 200\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        epoch_loss = train_loss/(batch_idx+1)\n",
    "        epoch_acc = 100.*correct/total\n",
    "        \n",
    "        if batch_idx % print_every == 0:\n",
    "            print('Epoch {}/{}, Iter {}/{}, Train Loss: {:.3f}, Train Accuracy: {:.3f}'.format(epoch, epochs, batch_idx, len(trainloader),\n",
    "                                                                                   epoch_loss, epoch_acc))\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8a7c5a",
   "metadata": {},
   "source": [
    "Write the testing funtion to get the test accuracy and test loss (minimal modifications to the training funtion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6bc579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(tqdm(testloader)):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    acc = 100.*correct/total\n",
    "    loss = test_loss/(batch_idx+1)\n",
    "    print('Test Accuracy: {:.3f}, Test Loss: {:.3f}'.format(acc, loss))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f4d9e9",
   "metadata": {},
   "source": [
    "Loop over all the epochs:\n",
    "\n",
    "- Run the training funtion\n",
    "- Save the losses and accuracies returned at each epoch\n",
    "- Run the test funtion\n",
    "- Save the model/Overwrite the previously saved one if the accuracy improved from the last epoch. Refer [here](https://pytorch.org/tutorials/beginner/saving_loading_models.html)\n",
    "\n",
    "**as a reference** for this model, you should get a **test accuracy** of ~ 76% after training for the first 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bdbc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0\n",
    "\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss, epoch_acc = train(epoch)\n",
    "    losses.append(epoch_loss)\n",
    "    accuracies.append(epoch_acc)\n",
    "    scheduler.step()\n",
    "    acc = test()\n",
    "    state = {'model': model.state_dict(),\n",
    "             'acc': acc,\n",
    "             'epoch': epoch}\n",
    "    if acc > best_acc: \n",
    "        torch.save(state, 'model.pth')\n",
    "        best_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af34911",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('train loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f90ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(accuracies)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('train accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb182e9",
   "metadata": {},
   "source": [
    "### Next Steps (advanced)\n",
    "The architecture we implemented is at its very basic, and dates back to 1998. Since 2012, there has been a tremendous amount of new CNN architectures, better regularization techniques and better activation funtions available. [this repo](https://github.com/kuangliu/pytorch-cifar) offers most of the models, and reports their accuracy on CIFAR10. If you are a pro, check out [this](https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/) also!\n",
    "\n",
    "Give it a try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78862f66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
